{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enhanced-thanksgiving",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per(n):\n",
    "    X = []\n",
    "    for i in range(1<<n):\n",
    "        s=bin(i)[2:]\n",
    "        s='0'*(n-len(s))+s\n",
    "        x = list(map(int,list(s)))\n",
    "        X.append(x)\n",
    "    return np.array(X)\n",
    "\n",
    "def p_x_given_y(M, X, Y, V, a):\n",
    "    \"\"\"\n",
    "        Q: (t, t), symmetric\n",
    "        V: (d, t)\n",
    "        a: (d, 1)\n",
    "        Y: (b, d)\n",
    "        X: (2**t, t)\n",
    "    \"\"\"\n",
    "    d_t = M.shape[0]\n",
    "    d_n = 2**d_t\n",
    "    d_d = V.shape[0]\n",
    "    d_b = Y.shape[0]\n",
    "    \n",
    "    Q = 0.5 * (M + M.T)\n",
    "    \n",
    "    assert V.shape == (d_d, d_t)\n",
    "    assert Q.shape == (d_t, d_t)\n",
    "    assert a.shape == (d_d, 1)\n",
    "    assert X.shape == (d_n, d_t)\n",
    "    assert Y.shape == (d_b, d_d)\n",
    "    \n",
    "    E1 = np.einsum('ki,ij,kj -> k', X, Q, X)\n",
    "    E2 = (V.dot(X.T) + a).T\n",
    "    E3 = E2.dot(Y.T)\n",
    "    logits = E1 + E3.T\n",
    "\n",
    "    assert logits.shape == (d_b, d_n)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 3     # dimension of discrete variable\n",
    "d = 4     # dimension of continuous variable\n",
    "n = 2**t  # dimension of discrete distribution\n",
    "b = 6     # batch size (for training later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t, d, n, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.random.random((t, t)).astype(np.float32)\n",
    "V = np.random.random((d, t)).astype(np.float32)\n",
    "a = np.random.random((d, 1)).astype(np.float32)\n",
    "#\n",
    "Y = np.random.random((b, d)).astype(np.float32)\n",
    "X = per(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_np = p_x_given_y(M, X, Y, V, a)\n",
    "print(logits_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-advice",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LHBarlowTwins(torch.nn.Module):\n",
    "    def  __init__(self, d_t, d_d, loss_param_scale=1., loss_param_lmbda=1.):\n",
    "        super(LHBarlowTwins, self).__init__()\n",
    "        self.d_t = d_t\n",
    "        self.d_d = d_d\n",
    "        self.d_n = 2**d_t\n",
    "        \n",
    "        self.M = torch.rand((d_t, d_t), requires_grad=True)\n",
    "        self.V = torch.rand((d_d, d_t), requires_grad=True)\n",
    "        self.a = torch.rand((d_d, 1), requires_grad=True)\n",
    "        \n",
    "        self.X = torch.Tensor(per(d_t))\n",
    "        \n",
    "        # affine = False -> no learnable parameters\n",
    "        self.bn = torch.nn.BatchNorm1d(self.d_n, affine=False)\n",
    "        \n",
    "        self.loss_param_scale = loss_param_scale\n",
    "        self.loss_param_lmbda = loss_param_lmbda\n",
    "    \n",
    "    def p_x_given_y(self, Y):\n",
    "        Q = 0.5 * (self.M + self.M.T)\n",
    "        E1 = torch.einsum('ki,ij,kj -> k', self.X, Q, self.X)\n",
    "        E2 = (self.V.matmul(self.X.T) + self.a).T\n",
    "        E3 = torch.matmul(E2, Y.T)\n",
    "        logits = E1 + E3.T\n",
    "        return logits\n",
    "    \n",
    "    def forward(self, y1, y2):\n",
    "        \n",
    "        z1 = self.p_x_given_y(y1)\n",
    "        z2 = self.p_x_given_y(y2)\n",
    "        #\n",
    "        # emprical cross-correlation matrix\n",
    "        c = self.bn(z1).T @ self.bn(z2)\n",
    "        c = c / y1.shape[0]\n",
    "\n",
    "        loss = self.loss(c)\n",
    "        return loss\n",
    "    \n",
    "    def from_numpy(self, M, V, a):\n",
    "        #\n",
    "        d_t = M.shape[0]\n",
    "        d_d = V.shape[0]\n",
    "        d_n = 2**d_t\n",
    "\n",
    "        assert M.shape == (d_t, d_t)\n",
    "        assert V.shape == (d_d, d_t)\n",
    "        assert a.shape == (d_d, 1)\n",
    "        \n",
    "        self.M = torch.tensor(M, requires_grad=True)\n",
    "        self.V = torch.tensor(V, requires_grad=True)\n",
    "        self.a = torch.tensor(a, requires_grad=True)\n",
    "        #\n",
    "        self.d_t = d_t\n",
    "        self.d_d = d_d\n",
    "        self.d_n = d_n\n",
    "    \n",
    "    def off_diagonal(self, x):\n",
    "        # return a flattened view of the\n",
    "        # off-diagonal elements of a square matrix\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "    def loss(self, c):\n",
    "        on_diag = torch.diagonal(\n",
    "            c).add_(-1).pow_(2).sum().mul(self.loss_param_scale)\n",
    "        off_diag = self.off_diagonal(c).pow_(\n",
    "            2).sum().mul(self.loss_param_scale)\n",
    "        #\n",
    "        loss = on_diag + self.loss_param_lmbda * off_diag\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LHBarlowTwins(t, d)\n",
    "model.from_numpy(M, V, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_pt = model.p_x_given_y(torch.Tensor(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = torch.rand((b, d))\n",
    "y2 = torch.rand((b, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(y1, y2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
